{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrapping data jobs from Seek\n",
    "\n",
    "### Outline of the project:\n",
    "On this project we will look for data specific jobs on Seek and use NLP to determine if what makes characterizes the job as high or low paying.\n",
    "\n",
    "To achieve this, we will classify the jobs as: High paying >= AUD 100.000 and low paying as < AUD 100.000\n",
    "\n",
    "To guarantee the project is reproducible and robust we will need at least 500 samples. If we cannot get that number from this webscraping we will use a pool of jobs that has been provided by GA.\n",
    "\n",
    "A second analysis will be made looking at the job descriptions and titles to ascertain what determines a job is related or not to data. This will be a more straightforward NLP processing task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Basic Libraries\n",
    "more should  be loaded as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scraping\n",
    "Data Scrapping was done from Seek on April 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "# from Ipython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping - First step\n",
    "Getting unique job url from seek.\n",
    "\n",
    "Will get job title and as much info as possible from this first page.\n",
    "\n",
    "Will use beautiful soup for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.seek.com.au/data-jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.seek.com.au/data-jobs'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.seek.com.auData Network Engineer'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'https://www.seek.com.au'+soup.find_all('a',{'class':'_2iNL7wI'})[int(j)].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Initiating empty list to append rows    \n",
    "link_list = []\n",
    "job_list = []\n",
    "def link_puller (url):\n",
    "\n",
    "    for i in range(1,500):\n",
    "#     BeautifulSoup\n",
    "        repeated_counter = 0\n",
    "#     getting to the right pages\n",
    "        url = 'https://www.seek.com.au/data-jobs?page='+str(i)\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "#     accessing individual jobs page\n",
    "        for j in range(1,20):\n",
    "\n",
    "            \n",
    "        #         initiating empty dict for this job\n",
    "            row = {}\n",
    "        #         Getting Job Title\n",
    "            row['title'] = soup.find_all('a',{'class':'_2iNL7wI'})[int(j)].text\n",
    "        #         Getting Job url\n",
    "            row['url'] = 'https://www.seek.com.au'+soup.find_all('a',{'class':'_2iNL7wI'})[int(j)].attrs['href']\n",
    "        #         Getting Job pay\n",
    "            try:\n",
    "                row['salary'] = soup.find_all('span',{'data-automation':'jobSalary'})[int(j)].text\n",
    "            except:\n",
    "                row['salary'] = \"No Information\"\n",
    "        \n",
    "            job_list.append(row)\n",
    "            print(len(job_list)) #Seeing the number of jobs pulled to check progress\n",
    "            \n",
    "            check = 'https://www.seek.com.au'+soup.find_all('a',{'class':'_2iNL7wI'})[int(j)].attrs['href']\n",
    "            \n",
    "            if check in link_list:\n",
    "                repeated_counter += 1\n",
    "                print(\" ----> REPEATED\", row['title'], row['url'])\n",
    "            else:\n",
    "                print(\" --> \", row['title'], row['url'])\n",
    "\n",
    "            # appending to the check after the check for this row\n",
    "            link_list.append(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_puller('https://www.seek.com.au/data-jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df = pd.DataFrame(job_list)\n",
    "link_df.to_csv('Link_list.csv',index=False)\n",
    "link_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the job postings are all unique\n",
    "Doing this step early will save us a lot of headache in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if I have two of the same \n",
    "df = pd.DataFrame(job_list)\n",
    "df = df.drop_duplicates(['url'], keep='first')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double checking to see if I have two of the same \n",
    "set_links = set(link_df.url)\n",
    "len(set_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all unique\n"
     ]
    }
   ],
   "source": [
    "# Triple checking to see if I have two of the same \n",
    "if link_df.shape[0] > len(set(link_df.url)):\n",
    "    print('different')\n",
    "else:\n",
    "    print('all unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Step\n",
    "Get the job info by going in to each url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, from this point onwards we have 3800 unique job postings. It is probable that most are not related to \"data\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = link_list[7]\n",
    "res = requests.get(url)        \n",
    "soup = BeautifulSoup(res.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty listto commit values\n",
    "raw_data=[]\n",
    "def job_puller (link_list):\n",
    "    loop_counter = 0\n",
    "    # looping thorugh each job\n",
    "    for j in link_list:\n",
    "        #getting how much in percentage we ran through\n",
    "        loop_counter += 1\n",
    "        loop_percent = (loop_counter/len(link_list))*100\n",
    "        print('%.2f' %loop_percent)\n",
    "        # getting soup\n",
    "        url = j\n",
    "        res = requests.get(url)        \n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        # Getting information out of jobs page\n",
    "        row = {}\n",
    "        \n",
    "        \n",
    "        # finding the company name and cleaning it up\n",
    "        try:\n",
    "            company = soup.find_all('span', {'class':\"_3FrNV7v _2QG7TNq E6m4BZb\"})[0].text\n",
    "        except:\n",
    "            company = \"Not Given\"\n",
    "        \n",
    "        # creating Company Column\n",
    "        row['company'] = company\n",
    "        \n",
    "        # cleaning up 'city'\n",
    "        try:\n",
    "            city = str(soup.find_all('strong', {'class':\"lwHBT6d\"})).replace('<strong class=\"lwHBT6d\">','').split('</strong>')[1][1:].replace(\"amp;\",\"\")\n",
    "        except:\n",
    "            city = \"Not Given\"\n",
    "        # Adding City Column\n",
    "        row['city'] = city\n",
    "        \n",
    "        # cleaning up 'job cat'\n",
    "        try:\n",
    "            cat = str(soup.find_all('strong', {'class':\"lwHBT6d\"})).replace('<strong class=\"lwHBT6d\">','').split('</strong>')[2].replace(\"amp;\",\"\")\n",
    "        except:\n",
    "            cat = \"Not Given\"\n",
    "        # Adding Cat Column\n",
    "        row['cat'] = cat            \n",
    "\n",
    "    \n",
    "        # full text pulling\n",
    "        full_text = soup.find_all('div', {'class':\"_2e4Pi2B\"})\n",
    "        full_text = str(full_text).replace('<div class=\"_2e4Pi2B\" data-automation=\"mobileTemplate\">','').replace('</div>','')\n",
    "\n",
    "        # removing html tags from the full page text for clarity\n",
    "        clean = re.compile('<.*?>')\n",
    "        full_text = re.sub(clean, '', full_text)\n",
    "        # creating full description column\n",
    "        row['full_desc'] = full_text[1:-1]\n",
    "        \n",
    "        # looking for salary --> This is a great way of doing it! Credit to Tom G for helping!\n",
    "        salary = soup.find_all('span', {'class':\"lwHBT6d\"})\n",
    "        salary = str(salary).replace(\",\",\"\")\n",
    "        try:\n",
    "            base_salary = re.search('([$])(\\d+(?:\\.\\d{2})?)', salary).groups()\n",
    "            base_salary = base_salary[1]\n",
    "        except:\n",
    "            base_salary = \"Not Given\"\n",
    "        # creating compensation column\n",
    "        row['pay'] = base_salary\n",
    "        \n",
    "        # looking for contract type\n",
    "        if \"Full Time\" in salary:\n",
    "            contract = \"Full Time\"\n",
    "        elif \"Casual\" in salary:\n",
    "            contract = \"Casual\"\n",
    "        elif \"Part Time\" in salary:\n",
    "            contract = \"Part Time\"\n",
    "        elif \"Contract/Temp\" in salary:\n",
    "            contract = \"Contract/Temp\"\n",
    "        else:\n",
    "            contract = \"Not Given\"\n",
    "        # Creating the contract_type column\n",
    "        row['contract'] = contract\n",
    "\n",
    "        # cleaning up 'location'\n",
    "        try:\n",
    "            location = str(soup.find_all('span', {'class':\"eBOHjGN\"})).replace('<span class=\"eBOHjGN\">','').replace('<span class=\"_2njvnpA\">','').split(\"</span>\")[1].replace(\"amp;\",\"\")\n",
    "        except:\n",
    "            location = \"Not Given\"\n",
    "        # Creating Location\n",
    "        row['location_desc'] = location\n",
    "\n",
    "           \n",
    "        # cleaning up 'job desc'\n",
    "        try:\n",
    "            job_des = str(soup.find_all('span', {'class':\"eBOHjGN\"})).replace('<span class=\"eBOHjGN\">','').replace('<span class=\"_2njvnpA\">','').split(\"</span>\")[3].replace(\"amp;\",\"\")\n",
    "        except:\n",
    "            job_des = \"Not Given\"\n",
    "        # Creating job description column\n",
    "        row['short_desc'] = job_des \n",
    "\n",
    "        \n",
    "        # Appending the row\n",
    "        raw_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_puller (link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making it in to a DF\n",
    "full_df = pd.DataFrame(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining with the previous scraped parts\n",
    "full_df = link_df.join(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>salary</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>cat</th>\n",
       "      <th>full_desc</th>\n",
       "      <th>pay</th>\n",
       "      <th>contract</th>\n",
       "      <th>location_desc</th>\n",
       "      <th>short_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deputy Project Managers x 2 (SFIA 4)</td>\n",
       "      <td>https://www.seek.com.au/job/41308040?type=prom...</td>\n",
       "      <td>Top $'s Paid ! Contract extensions likely !</td>\n",
       "      <td>Bright Consulting</td>\n",
       "      <td>ACT</td>\n",
       "      <td>, Information &amp; Communication Technology</td>\n",
       "      <td>Bright Consulting is Seeking two Deputy Projec...</td>\n",
       "      <td>Not Given</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Programme &amp; Project Management</td>\n",
       "      <td>Programme &amp; Project Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>https://www.seek.com.au/job/41346662?type=stan...</td>\n",
       "      <td>Top $'s Paid ! Contract extensions likely !</td>\n",
       "      <td>Quality People</td>\n",
       "      <td>Perth</td>\n",
       "      <td>, Information &amp; Communication Technology</td>\n",
       "      <td>Our client URGENTLY requires a Data Analyst fo...</td>\n",
       "      <td>Not Given</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Business/Systems Analysts</td>\n",
       "      <td>Business/Systems Analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>https://www.seek.com.au/job/41346677?type=stan...</td>\n",
       "      <td>Remuneration: $97,812 - $116,013 per annum</td>\n",
       "      <td>Quality People</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>, Information &amp; Communication Technology</td>\n",
       "      <td>Our client URGENTLY requires a Data Analyst fo...</td>\n",
       "      <td>Not Given</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Business/Systems Analysts</td>\n",
       "      <td>Business/Systems Analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>https://www.seek.com.au/job/41346675?type=stan...</td>\n",
       "      <td>Top $'s Paid ! Contract extensions likely !</td>\n",
       "      <td>Quality People</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>, Information &amp; Communication Technology</td>\n",
       "      <td>Our client URGENTLY requires a Data Analyst fo...</td>\n",
       "      <td>Not Given</td>\n",
       "      <td>Contract/Temp</td>\n",
       "      <td>Business/Systems Analysts</td>\n",
       "      <td>Business/Systems Analysts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst, Data Governance &amp; Management</td>\n",
       "      <td>https://www.seek.com.au/job/41343264?type=stan...</td>\n",
       "      <td>Top $'s Paid ! Contract extensions likely !</td>\n",
       "      <td>Cancer Institute NSW</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>, Government &amp; Defence</td>\n",
       "      <td>Employment Type: Permanent Full TimePosition C...</td>\n",
       "      <td>97812</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>CBD, Inner West &amp; Eastern Suburbs</td>\n",
       "      <td>Government - State</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0        Deputy Project Managers x 2 (SFIA 4)   \n",
       "1                                Data Analyst   \n",
       "2                                Data Analyst   \n",
       "3                                Data Analyst   \n",
       "4  Data Analyst, Data Governance & Management   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.seek.com.au/job/41308040?type=prom...   \n",
       "1  https://www.seek.com.au/job/41346662?type=stan...   \n",
       "2  https://www.seek.com.au/job/41346677?type=stan...   \n",
       "3  https://www.seek.com.au/job/41346675?type=stan...   \n",
       "4  https://www.seek.com.au/job/41343264?type=stan...   \n",
       "\n",
       "                                        salary               company  \\\n",
       "0  Top $'s Paid ! Contract extensions likely !     Bright Consulting   \n",
       "1  Top $'s Paid ! Contract extensions likely !        Quality People   \n",
       "2   Remuneration: $97,812 - $116,013 per annum        Quality People   \n",
       "3  Top $'s Paid ! Contract extensions likely !        Quality People   \n",
       "4  Top $'s Paid ! Contract extensions likely !  Cancer Institute NSW   \n",
       "\n",
       "        city                                       cat  \\\n",
       "0        ACT  , Information & Communication Technology   \n",
       "1      Perth  , Information & Communication Technology   \n",
       "2   Brisbane  , Information & Communication Technology   \n",
       "3   Adelaide  , Information & Communication Technology   \n",
       "4     Sydney                    , Government & Defence   \n",
       "\n",
       "                                           full_desc        pay  \\\n",
       "0  Bright Consulting is Seeking two Deputy Projec...  Not Given   \n",
       "1  Our client URGENTLY requires a Data Analyst fo...  Not Given   \n",
       "2  Our client URGENTLY requires a Data Analyst fo...  Not Given   \n",
       "3  Our client URGENTLY requires a Data Analyst fo...  Not Given   \n",
       "4  Employment Type: Permanent Full TimePosition C...      97812   \n",
       "\n",
       "        contract                      location_desc  \\\n",
       "0  Contract/Temp     Programme & Project Management   \n",
       "1  Contract/Temp          Business/Systems Analysts   \n",
       "2  Contract/Temp          Business/Systems Analysts   \n",
       "3  Contract/Temp          Business/Systems Analysts   \n",
       "4      Full Time  CBD, Inner West & Eastern Suburbs   \n",
       "\n",
       "                       short_desc  \n",
       "0  Programme & Project Management  \n",
       "1       Business/Systems Analysts  \n",
       "2       Business/Systems Analysts  \n",
       "3       Business/Systems Analysts  \n",
       "4              Government - State  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Done! Saving a CSV to ensure I dont loose it again\n",
    "# I'll consider this my corpus (pre cleaning and vectorizing)\n",
    "full_df.to_csv('full_file.csv', index=False)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3800, 11)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just quadruple checking that there are no duplicates\n",
    "full_df.drop_duplicates(['title','url'], keep='first').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, the Df looks good now.\n",
    "\n",
    "I will have a look and start cleaning next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "##### back-up plan/side project\n",
    "I just pulled a few full htmls. If I have the time I'll try to parse through them with regex to get out the info.\n",
    "\n",
    "Should be fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3781,)\n"
     ]
    }
   ],
   "source": [
    "# Using Selenium to  get all the HTML in the sites\n",
    "# Initiating selenium \n",
    "driver = webdriver.Chrome()\n",
    "# Creating empty listto commit values\n",
    "raw_html=[]\n",
    "# looping thorugh each job\n",
    "for j in link_list:\n",
    "#     print(j)\n",
    "    try:\n",
    "        driver.get(j)\n",
    "        sleep(1)\n",
    "#         Getting information out of jobs page\n",
    "        row = {}\n",
    "#             Building the Rows:\n",
    "#             Job title as advertised\n",
    "        row['full_html'] = driver.page_source\n",
    "#             Location of the advertised job\n",
    "    except:\n",
    "        row['full_html'] = 'NaN'\n",
    "    raw_html.append(row)\n",
    "#         job_list.append(jobs)\n",
    "#     print(len(raw_data))\n",
    "print(np.shape(raw_html))\n",
    "html = pd.DataFrame(raw_html)\n",
    "html.to_csv('html_part_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "driver.close()\n",
    "raw_df_1 = pd.read_csv('html_part_1.csv')\n",
    "# raw_df_2 = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"EDA\" and cleaning\n",
    "Checking what we got and possibly cleaning it a little.\n",
    "\n",
    "I just want to look at what we have before starting to clean it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('full_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Analyst                                           111\n",
       "Solution Architect                                          49\n",
       "Data Analyst                                                48\n",
       "Senior Business Analyst                                     39\n",
       "Technical Business Analyst                                  30\n",
       "Data Engineer                                               28\n",
       "Administration Assistant                                    15\n",
       "Data Scientist                                              14\n",
       "Administration Officer                                      12\n",
       "Business Intelligence Developer                             11\n",
       "Senior Data Engineer                                        11\n",
       "Customer Service Officer                                    11\n",
       "Clinical Nurse (Data Manager - Neonatal Intensive Care)     10\n",
       "Administrator                                               10\n",
       "Analyst                                                     10\n",
       "Research Assistant                                          10\n",
       "Data Architect                                               9\n",
       "Commercial Analyst                                           8\n",
       "Big Data Engineer                                            8\n",
       "Health Information Manager                                   7\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.title.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking ath the 50 job titles that have \n",
    "the most entries we see that we have a few that \n",
    "have no connection to data, such as electrician\n",
    "\n",
    "Lets take a closer look at the ones that are not so obvious and decide what to do.\n",
    "\n",
    "They are:\n",
    "- Administration Assistant\n",
    "- Administration Officer\n",
    "- Analyst\n",
    "- Administrator\n",
    "- Research Assistant\n",
    "- Commercial Analyst\n",
    "- Health Information Manager\n",
    "- Psychologist  Behaviour Support Team Leader \n",
    "- Intelligence Analyst (Signals)\n",
    "- Financial Analyst\n",
    "- Reporting Analyst\n",
    "- Pricing Analyst\n",
    "- Program Scheduler \n",
    "- Insolvency Analysts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNumber of positions available\\nUtilise your analytical and/or legal experience in a varied role - AS 4 level\\nCollegiate and supportive team environment\\n\\nAt ASIC there is a reason for everything we do, every law we regulate, every action we take, every interaction we have with industry and consumers. We're proud of the difference we make to Australia's economic reputation and wellbeing.\\nThe team\\nInsolvency Practitioners (IP) provide technical insolvency advice within ASIC and undertake three externally focused functions: Liquidator compliance- regulating the conduct of Registered Liquidators (RLs); the Assetless Administration Fund (AAF) - assessing liquidators' applications for funding; and Liaison activities - engagement with the insolvency profession and promoting ASIC's functions and expectations.\\nThe role\\nAs an Analyst, you will be required to:\\n\\nundertake compliance activities that monitor and regulate registered liquidator conduct, including transaction and risk-based surveillances and project work,\\nprovide advice to other Supervisory and Enforcement teams to assist ASIC to respond to insolvency related matters,\\nassist with liaison activities between ASIC and the insolvency profession, and\\nmeet documented key performance indicators.\\n\\nAs a valued member of the team, you will also:\\n\\nundertake additional responsibilities or tasks as required\\nwork professionally, positively and cooperatively as part of ASIC, and model the values of Accountability, Professionalism and Teamwork, and\\nundertake reasonable care for your own health and safety and that of others in the workplace that may be affected by your actions.\\n\\nRoles can be based in either - Sydney, Melbourne, Brisbane, Adelaide or Perth.\\nAbout you\\n\\nA Bachelor's degree in Accounting, Finance, Commerce or Law\\nQualified accountant (CAANZ or CPA) or admitted as a legal practitioner is desirable\\nExperience in aspects of external administration, including investigations and reporting\\nTechnical knowledge and practical experience in the area of insolvency law and practice in a commercial environment\\nExperience interpreting legislation, procedural manuals and guidelines\\nExperience working independently and being accountable for outcomes\\nPost graduate studies in insolvency law and practice would be highly regarded\\n\\nAbout ASIC\\nASIC can offer you a variety of interesting and challenging work. We provide the support for our employees to develop professionally and succeed.\\u202fASIC offers a range of programs such as flexible work practices and development programs which include a focus on gender equity and women in leadership.ASIC is committed to providing a diverse and inclusive workplace where the very best talent in Australia chooses to work. We encourage applicants from diverse backgrounds to apply, including Indigenous Australians and people with a disability.\\u202fTo work with us, you must be an Australian citizen, and be prepared to complete an ASIC Organisational Suitability Assessment (OSA) in addition to obtaining a Government Security Clearance which is issued by the Australian Government Security Vetting Agency (AGSVA).Please view the position description for more information or click ‘apply' to start your application.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(full_df.loc[full_df['title'] == 'Insolvency Analysts']['full_desc'])[3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jobs to drop:\n",
    "- APS4/5 Delivery and Engagement Officer\n",
    "- Postdoctoral Research Fellow (Biostatistician)\n",
    "- Property Manager\n",
    "- Customer Experience Specialist (Pharmaceuticals) - Sydney\n",
    "- Storeperson\n",
    "- Revenue Officer\n",
    "- Operational Services Officer                                                        \n",
    "- Office Support / Receptionist / Data Entry  \n",
    "- Graduate Geologist \n",
    "- Accounts Assistant\n",
    "- Training Coordinator\n",
    "- Automotive Technician/Mechanic\n",
    "- Specialist Business Standards Governance | Perth\n",
    "- Accountant                                                                          \n",
    "- Accounts Payable Officer                                                            \n",
    "- Research Associate/Fellow - Optimisation, Optimal Control or Operations Research\n",
    "- Bioanalytical Chemist\n",
    "- Warehouse Storeperson \n",
    "- Administration Officer - level 3\n",
    "- Product Lead\n",
    "- Accounts Payable \n",
    "- Administration & Office Support\n",
    "- Biostatistician\n",
    "- Geotechnical Engineer                                                 \n",
    "- Customer Advisor - Car Servicing                                      \n",
    "- Level 1/2  Network Integration Support (M17) \n",
    "- Administration Assistant - Not relatedto data\n",
    "- Administration Officer- Not relatedto data\n",
    "- Research Assistant\n",
    "- Health Information Manager\n",
    "- Psychologist  Behaviour Support Team Leader \n",
    "- Intelligence Analyst (Signals)\n",
    "- Administration\n",
    "- Insolvency Analysts\n",
    "- Self-employed Field Technicians\n",
    "- Bookkeeper\n",
    "- Payroll Officer\n",
    "- Acoustic Analyst Submariner\n",
    "- Assistant Accountant\n",
    "- Program Scheduler\n",
    "- Medical Receptionist\n",
    "- Service Desk Analyst Helpdesk Level 2\n",
    "- Application Support Analyst\n",
    "- Shift Lead Technician\n",
    "- Project Officer\n",
    "- Accounts Officer\n",
    "- Electrician\n",
    "- Purchasing Officer\n",
    "- Recepciotinist\n",
    "- Legal Officer-Child Advocate                               \n",
    "- Accommodation Manager\n",
    "- Legal Officer-Child Advocate                               \n",
    "- Accommodation Manager\n",
    "- Management Accountant\n",
    "- Laboratory Analyst\n",
    "- Water Resource Officer, Evaluation & Reporting             \n",
    "- ad Document Control Administration\n",
    "- Chief Scientist                                            \n",
    "- cument Controller \n",
    "- set Management Availability Focal\n",
    "- ter Resource Officer, Social Analyst\n",
    "- Laboratory Technician\n",
    "- Mine Surveyor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "jobs_to_drop = ['APS4/5 Delivery and Engagement Officer','Postdoctoral Research Fellow (Biostatistician)','Property Manager',\n",
    " 'Customer Experience Specialist (Pharmaceuticals) - Sydney', 'Storeperson','Revenue Officer','Operational Services Officer',\n",
    " 'Office Support / Receptionist / Data Entry','Graduate Geologist', 'Accounts Assistant','Training Coordinator',\n",
    " 'Automotive Technician/Mechanic','Specialist Business Standards Governance | Perth','Accountant','Accounts Payable Officer',\n",
    " 'Research Associate/Fellow - Optimisation, Optimal Control or Operations Research','Bioanalytical Chemist',\n",
    " 'Warehouse Storeperson','Administration Officer - level 3','Product Lead','Accounts Payable', 'Administration & Office Support',\n",
    " 'Biostatistician','Geotechnical Engineer','Customer Advisor - Car Servicing','Level 1/2  Network Integration Support (M17)',\n",
    " 'Administration Assistant - Not relatedto data','Administration Officer- Not relatedto data','Research Assistant',\n",
    " 'Health Information Manager','Psychologist  Behaviour Support Team Leader','Intelligence Analyst (Signals)','Administration',\n",
    " 'Insolvency Analysts','Self-employed Field Technicians','Bookkeeper','Payroll Officer','Acoustic Analyst Submariner',\n",
    " 'Assistant Accountant','Program Scheduler','Medical Receptionist','Service Desk Analyst Helpdesk Level 2',\n",
    " 'Application Support Analyst','Shift Lead Technician','Project Officer','Accounts Officer','Electrician','Purchasing Officer',\n",
    " 'Recepciotinist','Legal Officer-Child Advocate','Accommodation Manager','Legal Officer-Child Advocate','Accommodation Manager',\n",
    " 'Management Accountant','Laboratory Analyst','Water Resource Officer, Evaluation & Reporting',\n",
    " 'Lead Document Control Administration','Chief Scientist','Document Controller', 'Asset Management Availability Focal',\n",
    " 'Water Resource Officer', 'Social Analyst','Laboratory Technician','Mine Surveyor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = full_df.copy()\n",
    "for j in jobs_to_drop:\n",
    "    index_to_drop = list(full_df.loc[full_df['title'] == j].index)\n",
    "    try:\n",
    "        clean_df = clean_df.drop(index_to_drop)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3594, 11)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the description using regex\n",
    "Now to clean the columns, starting with the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the description to make a term matrix\n",
    "#  I'll make something that can be used in a lambda function that goes over the basics, like punctuation, lowercasing etc.\n",
    "def first_clean_description(text):\n",
    "    # Turning text in to lowercase\n",
    "    text = text.lower()\n",
    "    # removing puntuation from text\n",
    "    text = re.sub('[%s]' %re.escape(string.punctuation), '',text)\n",
    "    # removing numbers that are in the middle of the text\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # returnng the text clean\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying first round of cleaning on the title column\n",
    "clean_df['title'] = clean_df['title'].apply(lambda x: first_clean_description(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying first round of cleaning on the description column\n",
    "clean_df['full_desc'] = clean_df['full_desc'].apply(lambda x: first_clean_description(str(x)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'working for amp \\nworking for amp means being part of a company that values diverse thinking encourages collaboration and promotes innovation \\xa0it’s an environment that offers challenging and exciting work as well as opportunities for professional growth we’re flexible enough to allow you to make the most of your life both professionally and personally \\nwe are looking for those that have the courage and agility to navigate changing and complex environments so that we can deliver the best solutions for our customers we value people with integrity an innate willingness to help others and an eagerness to perform to the best of their abilities\\xa0\\nwe’re transforming our business and we need people like you to join us on this journey\\n\\xa0\\nabout the role\\nas a key technical role reporting to the platform super manager – cloud business applications the technical business analyst is accountable for working closely with servicenow sme team integration engineers developers and testers to design document and test core extensible servicenow configurations \\nthe technical business analyst is expected to liaise with key stakeholders to deliver technical documentation and test support at times the analyst will be expected to use their sme knowledge of servicenow to help solution design on the platform\\n\\xa0\\nkey responsibilities\\n\\nstaying abreast of servicenow platform requirements and working with vendor and industry partners to explore process and functional improvements that can enhance the service offering of applications currently in use\\nproviding thought leadership for servicenow design and best practice\\npartnering with sponsoring projects architects developers and other design professionals to define and provide the most appropriate and documented technical requirements for servicenow changes\\ngathering and documenting technical business requirements by working closely with project sponsors and business owners as well as fellow architects developers and testers\\ndocumenting and defining servicenow user interfaces that incorporate business rules for the development of reusable servicenow assets\\nconducting data modelling and data analysis to help validate business and solution requirements\\ndefining and managing the requirements through the delivery lifecycle to meet business needs\\nassisting in the development and maintenance of servicenow actively seeking new ways and approached to improve the breadth and efficiency of services\\nassisting development managers with the estimation of solutions and the prioritisation of functionality against desired cost benefit outcomes\\nbuilding relationships and developing platform advocacy across a variety of stakeholders including internal customers vendor and partners\\nworking with the development team to translate business requirements into functional designs and architectures that meet stakeholder needs\\n\\ncapabilities amp experience\\ntechnical capabilities\\n\\nskills needed to deliver the key services provided by the team\\nbusiness analysis amp traceability management\\nitil amp service management\\nservicenow sme link removed\\n\\nservicenow certified system administrator – optional\\n\\nknowledge of itsm processes within servicenow\\n\\nwellbeing amp benefits \\nas a company that values wellbeing we offer a range of great benefits to support you financially professionally and personally these include access to a wide range of flexible working options including the ability to purchase extra leave retail discounts onsite wellbeing centre including a gym sydney office employee assistance program competitive home loan rates leading superannuation contribution discounted financial advice and personal insurance\\n\\xa0\\ninclusion amp diversity\\namp recognises individual differences and welcomes people from a variety of life and work experiences the diversity of our people is core to our ability to innovate grow and to fulfil our collective aspiration of helping people to own their tomorrow a natural curiosity a respect for differences and a growth mindset are valued at amp\\n\\xa0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clean_df.loc[clean_df['title'] == 'technical business analyst']['full_desc'])[5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a few problems, will do a second round of cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the description to make a term matrix\n",
    "#  There is still some stuff to clean out\n",
    "def second_clean_description(text):\n",
    "    # taking out special caracters\n",
    "    text = re.sub('\\n', '', text)\n",
    "    # taking out special caracters\n",
    "    text = re.sub('\\xa0', '', text)\n",
    "    # taking out special caracters\n",
    "    text = re.sub(\"'\", '', text)\n",
    "    # removing email addresses\n",
    "    text = re.sub('([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)' , '',text)\n",
    "    # returnng the text clean\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying second round of cleaning on the description column\n",
    "clean_df['full_desc'] = clean_df['full_desc'].apply(lambda x: second_clean_description(str(x)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'working for amp working for amp means being part of a company that values diverse thinking encourages collaboration and promotes innovation it’s an environment that offers challenging and exciting work as well as opportunities for professional growth we’re flexible enough to allow you to make the most of your life both professionally and personally we are looking for those that have the courage and agility to navigate changing and complex environments so that we can deliver the best solutions for our customers we value people with integrity an innate willingness to help others and an eagerness to perform to the best of their abilitieswe’re transforming our business and we need people like you to join us on this journeyabout the roleas a key technical role reporting to the platform super manager – cloud business applications the technical business analyst is accountable for working closely with servicenow sme team integration engineers developers and testers to design document and test core extensible servicenow configurations the technical business analyst is expected to liaise with key stakeholders to deliver technical documentation and test support at times the analyst will be expected to use their sme knowledge of servicenow to help solution design on the platformkey responsibilitiesstaying abreast of servicenow platform requirements and working with vendor and industry partners to explore process and functional improvements that can enhance the service offering of applications currently in useproviding thought leadership for servicenow design and best practicepartnering with sponsoring projects architects developers and other design professionals to define and provide the most appropriate and documented technical requirements for servicenow changesgathering and documenting technical business requirements by working closely with project sponsors and business owners as well as fellow architects developers and testersdocumenting and defining servicenow user interfaces that incorporate business rules for the development of reusable servicenow assetsconducting data modelling and data analysis to help validate business and solution requirementsdefining and managing the requirements through the delivery lifecycle to meet business needsassisting in the development and maintenance of servicenow actively seeking new ways and approached to improve the breadth and efficiency of servicesassisting development managers with the estimation of solutions and the prioritisation of functionality against desired cost benefit outcomesbuilding relationships and developing platform advocacy across a variety of stakeholders including internal customers vendor and partnersworking with the development team to translate business requirements into functional designs and architectures that meet stakeholder needscapabilities amp experiencetechnical capabilitiesskills needed to deliver the key services provided by the teambusiness analysis amp traceability managementitil amp service managementservicenow sme link removedservicenow certified system administrator – optionalknowledge of itsm processes within servicenowwellbeing amp benefits as a company that values wellbeing we offer a range of great benefits to support you financially professionally and personally these include access to a wide range of flexible working options including the ability to purchase extra leave retail discounts onsite wellbeing centre including a gym sydney office employee assistance program competitive home loan rates leading superannuation contribution discounted financial advice and personal insuranceinclusion amp diversityamp recognises individual differences and welcomes people from a variety of life and work experiences the diversity of our people is core to our ability to innovate grow and to fulfil our collective aspiration of helping people to own their tomorrow a natural curiosity a respect for differences and a growth mindset are valued at amp'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(clean_df.loc[clean_df['title'] == 'technical business analyst']['full_desc'])[5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good enough! Next Column, Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the description to make a term matrix\n",
    "#  I'll make something that can be used in a lambda function that goes over the basics, like punctuation, lowercasing etc.\n",
    "def first_clean_salary(text):\n",
    "    # removing puntuation from text\n",
    "    text = re.sub('[%s]' %re.escape(string.punctuation), '',text)\n",
    "    # removing text from numbers\n",
    "    text = re.sub('[a-zA-Z]*', '', text)\n",
    "    # returnng the text clean\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['salary'] = clean_df['salary'].apply(lambda x: first_clean_salary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    2455\n",
       "                      51\n",
       "                      36\n",
       "                      32\n",
       "                      31\n",
       "                    ... \n",
       "4546  6153             1\n",
       "800  900               1\n",
       "  800                  1\n",
       "140000  149999         1\n",
       "750  800               1\n",
       "Name: salary, Length: 676, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not the best, but I am not sure hot to make it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Not Given    2695\n",
       "60000          27\n",
       "700            26\n",
       "100            23\n",
       "50000          23\n",
       "             ... \n",
       "715             1\n",
       "69212           1\n",
       "88410.40        1\n",
       "68000.00        1\n",
       "1300            1\n",
       "Name: pay, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['pay'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ", Information & Communication Technology    1600\n",
       ", Administration & Office Support            277\n",
       ", Government & Defence                       223\n",
       ", Accounting                                 215\n",
       ", Banking & Financial Services               209\n",
       ", Manufacturing, Transport & Logistics       117\n",
       ", Marketing & Communications                 112\n",
       ", Healthcare & Medical                       106\n",
       ", Mining, Resources & Energy                 100\n",
       ", Science & Technology                        71\n",
       ", Engineering                                 63\n",
       ", Consulting & Strategy                       61\n",
       ", Sales                                       54\n",
       ", Human Resources & Recruitment               52\n",
       ", Trades & Services                           42\n",
       ", Insurance & Superannuation                  42\n",
       "Not Given                                     35\n",
       ", Retail & Consumer Products                  34\n",
       ", Call Centre & Customer Service              32\n",
       ", Education & Training                        31\n",
       ", Community Services & Development            28\n",
       ", Construction                                24\n",
       ", Real Estate & Property                      24\n",
       ", Legal                                       15\n",
       ", Advertising, Arts & Media                    8\n",
       ", CEO & General Management                     5\n",
       ", Design & Architecture                        5\n",
       ", Farming, Animals & Conservation              5\n",
       ", Hospitality & Tourism                        3\n",
       ", Sport & Recreation                           1\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the description to make a term matrix\n",
    "#  I'll make something that can be used in a lambda function that goes over the basics, like punctuation, lowercasing etc.\n",
    "def first_clean_salary(text):\n",
    "    # removing puntuation from text\n",
    "    text = re.sub('[%s]' %re.escape(string.punctuation), '',text)\n",
    "    # removing & from numbers\n",
    "    text = re.sub('&*', '', text)\n",
    "    # returnng the text clean\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Cat a little.\n",
    "clean_df['cat'] = clean_df['cat'].str.strip(',').str.strip(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping rows that have no pay information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the jobs that have no pay information\n",
    "lean_df = clean_df.drop(list(clean_df.loc[clean_df['pay'] == 'Not Given'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_clean_pay(text):\n",
    "    # removing puntuation from text\n",
    "    text = re.sub('[%s]' %re.escape(string.punctuation), '',text)\n",
    "    # returnng the text clean\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_df['pay'] = lean_df['pay'].apply(lambda x: first_clean_pay(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the number in to integers\n",
    "lean_df['pay'] = lean_df['pay'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Full Time        584\n",
       "Contract/Temp    280\n",
       "Part Time         20\n",
       "Casual            15\n",
       "Name: contract, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lean_df['contract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping salary column as it has no useful\n",
    "lean_df.drop('salary', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure that the columns that will be dummified have only one word on their rows\n",
    "# This will make it so that the understanding of the tokenized works makes more sense, hopefully\n",
    "lean_df.city = lean_df.city.str.strip(' ').apply(lambda x: x.replace(' ','_').replace('&',''))\n",
    "lean_df.cat = lean_df.cat.str.strip(' ').apply(lambda x: x.replace(' ','_').replace('&',''))\n",
    "lean_df.contract = lean_df.contract.str.strip(' ').apply(lambda x: x.replace(' ','_').replace('&',''))\n",
    "lean_df.location_desc = lean_df.location_desc.str.strip(' ').apply(lambda x: x.replace(' ','_').replace('&',''))\n",
    "lean_df.short_desc = lean_df.short_desc.str.strip(' ').apply(lambda x: x.replace(' ','_').replace('&',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping jobs that pay less tha 60k. Likely pay per day or have different remmuneration\n",
    "model_df = lean_df.loc[lean_df['pay'] > 60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving CSV, just in case...\n",
    "model_df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Okay! lets do some CountVectorizing and see what we get!\n",
    "\n",
    "I want to get the top words, unique words used (Specific/technical vocabulary)\n",
    "\n",
    "First I will tokenize (ConutVectorizer) then I'll run some models to test the best with this type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "# Using NB models to test the tokenizer\n",
    "# And LogisticRegression because the target is binary\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Thing will be to determine the target\n",
    "# I will try to do a classification model using a treshold to determine high/low salary\n",
    "# creating a column for low/high salary\n",
    "model_df['salary'] = 0\n",
    "model_df.loc[model_df['pay'] >= 100000, 'salary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    156\n",
       "1    150\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything over 100K is high. Pretty good class division!\n",
    "model_df['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the split above we can see that we only have 306 jobs.\n",
    "\n",
    "As stated on the begining of the project, we need at least 500 jobs to be able to have an acceptable result.\n",
    "It is likely that we did not chieve the 500 jobs due to the moment in time the scape was made. It will be interesting to run the same code in te future and see how many jobs we get.\n",
    "\n",
    "For this project we will start a new notebook using the CSV provided by GA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
